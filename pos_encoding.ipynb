{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtester.dataSource.csv_data_source import CsvDataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "cachedFolderName = '/data/'\n",
    "dataSetId = 'trainingData1'\n",
    "startDate = '2017/01/06'\n",
    "endDate = '2017/02/09'\n",
    "instrumentIds = ['MQK']\n",
    "downloadUrl = 'https://github.com/Auquan/auquan-historical-data/raw/master/qq2Data'\n",
    "\n",
    "ds = CsvDataSource(cachedFolderName='historicalData/',\n",
    "                             dataSetId=dataSetId,\n",
    "                             instrumentIds=instrumentIds,\n",
    "                             downloadUrl = downloadUrl,\n",
    "                             timeKey = 'datetime',\n",
    "                             timeStringFormat = '%Y-%m-%d %H:%M:%S',\n",
    "                             startDateStr=startDate,\n",
    "                             endDateStr=endDate,\n",
    "                             liveUpdates=False,\n",
    "                             pad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading our data\n",
    "def loadData(ds, id):\n",
    "    data = ds._bookDataByInstrument[id].getBookData()\n",
    "\n",
    "    data['Stock Price'] =  (data['stockTopBidPrice'] +\\\n",
    "                           data['stockTopAskPrice']) / 2.0\n",
    "    data['Future Price'] = (data['futureTopBidPrice'] +\\\n",
    "                           data['futureTopAskPrice']) / 2.0\n",
    "    data['Y(Target)'] = data['basis'].shift(-5)\n",
    "    del data['benchmark_score']\n",
    "    del data['FairValue']\n",
    "    return data\n",
    "\n",
    "data = loadData(ds,instrumentIds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "dataSetId =  'trainingData1'\n",
    "ds_training = CsvDataSource(cachedFolderName='historicalData/',\n",
    "                             dataSetId=dataSetId,\n",
    "                             instrumentIds=instrumentIds,\n",
    "                             downloadUrl = downloadUrl,\n",
    "                             timeKey = 'datetime',\n",
    "                             timeStringFormat = '%Y-%m-%d %H:%M:%S',\n",
    "                             liveUpdates=False,\n",
    "                             pad=True)\n",
    "\n",
    "training_data = loadData(ds_training, instrumentIds[0])\n",
    "\n",
    "# Validation Data\n",
    "dataSetId =  'trainingData2'\n",
    "ds_validation = CsvDataSource(cachedFolderName='historicalData/',\n",
    "                             dataSetId=dataSetId,\n",
    "                             instrumentIds=instrumentIds,\n",
    "                             downloadUrl = downloadUrl,\n",
    "                             timeKey = 'datetime',\n",
    "                             timeStringFormat = '%Y-%m-%d %H:%M:%S',\n",
    "                             liveUpdates=False,\n",
    "                             pad=True)\n",
    "validation_data = loadData(ds_validation, instrumentIds[0])\n",
    "\n",
    "# Test Data\n",
    "dataSetId =  'trainingData3'\n",
    "ds_test = CsvDataSource(cachedFolderName='historicalData/',\n",
    "                             dataSetId=dataSetId,\n",
    "                             instrumentIds=instrumentIds,\n",
    "                             downloadUrl = downloadUrl,\n",
    "                             timeKey = 'datetime',\n",
    "                             timeStringFormat = '%Y-%m-%d %H:%M:%S',\n",
    "                             liveUpdates=False,\n",
    "                             pad=True)\n",
    "out_of_sample_test_data = loadData(ds_test, instrumentIds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(data, period):\n",
    "    data['Y(Target)'] = data['basis'].rolling(period).mean().shift(-period)\n",
    "    if 'FairValue' in data.columns:\n",
    "        del data['FairValue']\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "period = 5\n",
    "prepareData(training_data, period)\n",
    "prepareData(validation_data, period)\n",
    "prepareData(out_of_sample_test_data, period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(dataDf, period):\n",
    "    return dataDf.sub(dataDf.shift(period), fill_value=0)\n",
    "\n",
    "def ewm(dataDf, halflife):\n",
    "    return dataDf.ewm(halflife=halflife,ignore_na=False,min_periods=0,adjust=True).mean()\n",
    "\n",
    "def rsi(data, period):\n",
    "    data_upside = data.sub(data.shift(1), fill_value=0)\n",
    "    data_downside = data_upside.copy()\n",
    "    data_downside[data_upside > 0] = 0\n",
    "    data_upside[data_upside < 0] = 0\n",
    "    avg_upside = data_upside.rolling(period).mean()\n",
    "    avg_downside = - data_downside.rolling(period).mean()\n",
    "    rsi = 100 - (100 * avg_downside / (avg_downside + avg_upside))\n",
    "    rsi[avg_downside == 0] = 100\n",
    "    rsi[(avg_downside == 0) & (avg_upside == 0)] = 0\n",
    "\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_again(data):\n",
    "    basis_X = pd.DataFrame(index = data.index, columns =  [])\n",
    "    \n",
    "    basis_X['mom10'] = difference(data['basis'],11)\n",
    "    \n",
    "    basis_X['emabasis2'] = ewm(data['basis'],2)\n",
    "    basis_X['emabasis5'] = ewm(data['basis'],5)\n",
    "    basis_X['emabasis10'] = ewm(data['basis'],10)\n",
    "\n",
    "    basis_X['basis'] = data['basis']\n",
    "\n",
    "    basis_X['totalaskvolratio'] = (data['stockTotalAskVol']-data['futureTotalAskVol'])/100000\n",
    "    basis_X['totalbidvolratio'] = (data['stockTotalBidVol']-data['futureTotalBidVol'])/100000\n",
    "    \n",
    "    basis_X = basis_X.fillna(0)\n",
    "    \n",
    "    basis_y = data['Y(Target)']\n",
    "    basis_y.dropna(inplace=True)\n",
    "    \n",
    "    print(\"Any null data in y: %s, X: %s\"%(basis_y.isnull().values.any(), basis_X.isnull().values.any()))\n",
    "    print(\"Length y: %s, X: %s\"%(len(basis_y.index), len(basis_X.index)))\n",
    "    \n",
    "    return basis_X, basis_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_X_test, basis_y_test = create_features_again(validation_data)\n",
    "basis_X_train, basis_y_train = create_features_again(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = keras.models.Sequential()\n",
    "model_cnn.add(keras.layers.InputLayer(input_shape=[7, 1]))\n",
    "for dilation_rate in (1, 2, 4):\n",
    "    model_cnn.add(\n",
    "      keras.layers.Conv1D(filters=4,\n",
    "                          kernel_size=2,\n",
    "                          strides=1,\n",
    "                          dilation_rate=dilation_rate,\n",
    "                          padding=\"causal\",\n",
    "                          activation=\"relu\")\n",
    "    )\n",
    "model_cnn.add(keras.layers.Conv1D(filters=2, kernel_size=1))\n",
    "model_cnn.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "model_cnn.add(keras.layers.Flatten())\n",
    "model_cnn.add(keras.layers.Dense(1))\n",
    "model_cnn.compile(optimizer='adam', loss='mae')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
