{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import UpSampling1D\n",
    "from tensorflow.keras.layers import AveragePooling1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "print('X:', X)\n",
    "print('y:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dimension = 1,\n",
    "dilations = (1, 2, 4, 8, 16),\n",
    "nb_filters = 20,\n",
    "kernel_size = 20,\n",
    "nb_stacks = 1,\n",
    "padding = 'causal',\n",
    "dropout_rate = 0.00,\n",
    "filters_conv1d = 8,\n",
    "activation_conv1d = 'linear',\n",
    "latent_sample_rate = 42,\n",
    "pooler = AveragePooling1D,\n",
    "lr = 0.001,\n",
    "conv_kernel_init = 'glorot_normal',\n",
    "loss = 'logcosh',\n",
    "use_early_stopping = False,\n",
    "error_window_length = 128,\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcn import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Input(shape=(1050, 1))\n",
    "\n",
    "# Put signal through TCN. Output-shape: (batch,sequence length, nb_filters)\n",
    "tcn_enc = TCN(nb_filters=nb_filters, kernel_size=kernel_size, nb_stacks=1, dilations=[1, 2, 4, 8, 16], \n",
    "                padding='causal', use_skip_connections=True, dropout_rate=dropout_rate, return_sequences=True,\n",
    "                kernel_initializer='glorot_normal', name='tcn-enc')(i)\n",
    "\n",
    "# Now, adjust the number of channels...\n",
    "enc_flat = Conv1D(filters=filters_conv1d, kernel_size=1, activation=activation_conv1d, padding='causal')(tcn_enc)\n",
    "\n",
    "## Do some average (max) pooling to get a compressed representation of the time series (e.g. a sequence of length 8)\n",
    "enc_pooled = pooler(pool_size=latent_sample_rate, strides=None, padding='causal', data_format='channels_last')(enc_flat)\n",
    "\n",
    "# If you want, maybe put the pooled values through a non-linear Activation\n",
    "enc_out = Activation(\"linear\")(enc_pooled)\n",
    "model_tcn = Model(inputs=[i], outputs=[enc_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a neural network to invert feature representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have a short sequence, which we will upsample again and then try to reconstruct the original series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Input(batch_shape=enc_out.shape)\n",
    "# Now we should have a short sequence, which we will upsample again and then try to reconstruct the original series\n",
    "dec_upsample = UpSampling1D(size=latent_sample_rate)(enc_out)\n",
    "\n",
    "dec_reconstructed = TCN(nb_filters=nb_filters, kernel_size=kernel_size, nb_stacks=nb_stacks, dilations=dilations, \n",
    "                        padding=padding, use_skip_connections=True, dropout_rate=dropout_rate, return_sequences=True,\n",
    "                        kernel_initializer=conv_kernel_init, name='tcn-dec')(dec_upsample)\n",
    "\n",
    "# Put the filter-outputs through a dense layer finally, to get the reconstructed signal\n",
    "o = Dense(ts_dimension, activation='linear')(dec_reconstructed)\n",
    "\n",
    "model = Model(inputs=[i], outputs=[o])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d6c8a90009f980302c012bd64503e966cbb5885067e3c60305a8569cc587575"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
